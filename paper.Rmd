---
title: |
  Burning sage: Reversing the curse of dimensionality in the visualisation of high-dimensional data
type: Article
author:
  - name: Ursula Laa
    affil: a, b
    email: ursula.laa@monash.edu
  - name: Dianne Cook
    affil: b
    email: dicook@monash.edu
  - name: Stuart Lee
    affil: b, c
    email: stuart.lee1@monash.edu
affiliation:
  - num: a
    address: |
      School of Physics and Astronomy, Monash University
  - num: b
    address: |
      Department of Econometrics and Business Statistics, Monash University
  - num: c
    address: |
      Molecular Medicine Division, Walter and Eliza Hall Institute, Parkville, Australia
bibliography: biblio.bib
geometry: margin=2.5cm
abstract: |
  XXX
keywords: |
  data visualisation; grand tour; statistical computing; statistical graphics; multivariate data; dynamic graphics
header-includes: |
  \usepackage{hyperref}
  \usepackage[utf8]{inputenc}
  \def\tightlist{}
  \usepackage{setspace}
output: rticles::tf_article
keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(gridExtra)
library(ggforce)
library(tourr)
```

\doublespacing
# Introduction

The notion of a "curse of dimensionality" was originally introduced in @BellmanRichard1961 to describe the exponential growth in difficulty for optimization as number of dimensions increases. This affects sampling in high-dimensions. The volume of the space grows exponentially, with dimension, and since it is not typically feasible to increase the number of samples accordingly, the density of points decreases. The effect is that most points will be far from the sample mean, on the edge of the sample space. @doi:10.1111/j.1467-9868.2005.00510.x have shown that in the extreme case of high-dimension, low-sample size data, observations are on the vertices of a simplex. 

<!-- This causes problems in different domains. An important example in statistics is cluster analysis. Since the distance between any two points in a distribution becomes approximately constant, new methods are needed to cluster points in a high-dimensional space (see e.g. @Steinbach2004).-->

@Donoho00, conversely, considers the curse of dimensionality as a blessing, because the sparsity can be leveraged for computational efficiency. This is used in regularization methods, like lasso, to penalize model complexity. The penalty results in shrinking (some of) the parameter estimates towards zero.<!-- In ridge regression we obtain a global shrinkage, while Lasso can be thought of as variable selection and will shrink some of the estimates to zero. XXX mention concentration of measures?-->

Paradoxically, the curse of dimensionality inverts for dimension reduction, and affects the resulting visualizations. For low-dimensional linear projections of high-dimensional data, most projections will show approximately Gaussian distributions of the data, with observations concentrating in the center [@diaconis1984]. In projection pursuit, this motivated the development of indexes showing departure from normality. For high-dimension low-sample size data @10.2307/27639976,@10.1093/biomet/asp084 call this "data piling": all observations are in a single point in certain low-dimensional projections. These issues also persist with non-linear dimension reduction techniques. This is often referred to as the "crowding problem", which methods like t-Distributed Stochastic Neighbor Embedding (t-SNE) [@tsne] aim to alleviate.

XXX FIX - how can I make the contours better? Maybe get radial density and draw as circles?
For illustration we show two-dimensional linear projections of points sampled uniformly within hyperspheres in $p=3, 10, 100$ dimensions in Figure \ref{fig:density}. All distributions are uniform within the maximum radius $R=1$, but the projected points start piling near the center as $p$ increases.

```{r density, fig.cap="Two-dimensional projections of 10k points sampled uniformly within a $p$-dimensional hyperspheres, for $p=3, 10, 100$. The density is shown both through transparancy of the projected points, and as contour lines.", out.width="95%", fig.align = "center"}

set.seed(2020)

lbl <- c("p=3", "p=10", "p=100")
names(lbl) <- c("p3", "p10", "p100")

n <- 10000

# sample points, only keep first two components for 2D projection
p3 <- geozoo::sphere.solid.random(3, n)$points[, c(1,2)]
p10 <- geozoo::sphere.solid.random(10, n)$points[, c(1,2)]
p100 <- geozoo::sphere.solid.random(100, n)$points[, c(1,2)]
colnames(p3) <- c("x", "y")
colnames(p10) <- c("x", "y")
colnames(p100) <- c("x", "y")

proj_points <- as_tibble(rbind(p3, p10, p100)) %>%
  add_column(p = c(rep(3, n), rep(10, n), rep(100, n)))


ggplot(proj_points, aes(x, y)) +
  geom_point(alpha=0.02) + 
  geom_density2d(bins = 7, contour_var = "ndensity") +
  coord_fixed() +
  theme_bw() +
  facet_wrap(~p, labeller = labeller(name = lbl)) +
  guides(color = FALSE) +
  theme(axis.title.x=element_blank(), axis.title.y=element_blank())

```

In this work we address the piling in low-dimensional linear projections, which is in particular a barrier for viewing high-dimensional distributions with tour methods [@As85,@BCAH05]. Tours show interpolated sequences of low-dimensional projections of the data. When exploring a dataset with a tour we look at the distribution from different sides and want to discover features that may be visible from a specific viewing angle. However, these features may easily be hidden if most of the observations pile up near the center, while a large fraction of the plotting canvas will only show sparse outlying points. To counteract the effect, we introduce a radial transformation that redistributes data points after projecting them onto a two-dimensional plane, essentially zooming in near the center of the distribution.

XXXX needs to be updated
The paper is structured as follows: the radial transformation is described in Section \ref{sec:method}, the implementation as a new display function for the tourr package is described in Section \ref{sec:implementation}, and we show applications in Section \ref{sec:application}. We conclude in Section \ref{sec:concl}.

XXX probably remove this, for now keeping it in for reference
see also discussion in https://mc-stan.org/users/documentation/case-studies/curse-dims.html on the average length of multivariate normal vector for large $p$, relation to "concentration of measures".


# Burning sage algorithm {#sec:method}

To better understand the seemingly contradictory low density of points near the center in the high-dimensional space, versus the piling in low-dimensional projections, we consider the projected volume. For this, it is useful to think of the data as being distributed in a hypersphere, i.e. all data points are within a specified distance from the center. Compared to the common assumption of a distribution in a box or hypercube this has the advantage of being rotation invariant, and more accurately captures commonly observed distributions.

We can picture the linearly projected volume starting from a 3D sphere. In any 2D projection a large fraction of the volume will be projected onto a small region near the center of the resulting disc, as a consequence of the shape of the sphere. The volume will be further concentrated when projecting onto 1D instead. The same intuition holds as we increase the number of original dimensions that are projected down to one or two dimensions for visualization, with increasing fractions of the volume being projected onto a small area around the center, see Figure \ref{fig:density} for illustration.

Here we introduce a radial transformation that redistributes the projected points, such that equal volume in the original ($p$-dimensional) space is projected onto equal area in a 2-dimensional projection. Note that it is straightforward to generalize this for $d$-dimensional projections by mapping onto equal $d$-dimensional volume instead.

## Relative volume

The radial dependence of the projected volume was described in @Laa:2020wkm through the ratio of the total volume of a $p$-dimensional sphere of radius $R$, $V(R, p)$ and its projected volume within a 2-dimensional radius $r$, $V_{2D}(r, R, p)$,
\begin{equation}
V^{rel}_{2D} (r, p, R) = \frac{V_{2D}(r, R, p)}{V(R, p)} = 1 - \left(1-\left(\frac{r}{R}\right)^2\right)^{p/2}.
\label{eq:cdf}
\end{equation}
This ratio is of particular interest because it gives the 2-dimensional radial cumulative distribution function (CDF) of points when assuming a uniform distribution within the $p$-dimensional hypersphere.

We compare $V^{rel}_{2D} (r, p, R)$ to the relative volume within a radius $r$ in the full hypersphere,
\begin{equation}
V^{rel}_{pD} (r, p, R) = \frac{V(r, p)}{V(R, p)} = \left({\frac{r}{R}}\right)^p,
\end{equation}
to illustrate the opposing effects on their distribution. This comparison is shown in Fig. \ref{fig:cdf}, for $p=3, 10, 100$. The left graph shows $V^{rel}_{pD} (r, p, R)$ and the right graph $V^{rel}_{2D} (r, p, R)$. We clearly see the opposing behavior of the two functions as $p$ increases. While $V^{rel}_{pD} (r, p, R)$ concentrates more and more towards large values of $r/R$, $V^{rel}_{2D} (r, p, R)$ has the opposite behavior. This concentration near the center of the disk is the result of integrating over all orthogonal directions when projecting onto the plane, and should be reversed by our radial transformation of the projected points.

```{r cdf, fig.cap="Comparing the relative volume of a $p$ dimensional hypersphere captured within a radius $r$, in the $p$-dimensional space (left) and in a 2-dimensional projection (right), for $p=3, 10, 100$. While most of the volume is squeezed towards larger values of $r$ as $p$ increases, the projected volume gets concentrated near the center instead.", fig.height=2.2, fig.width=6, out.width = "90%", fig.align = "center"}

cdf_2 <- function(p){
  function(r){
    1 - (1 - r^2)^(p/2)
  }
}

cdf_p <- function(p){
  function(r){
    r^p
  }
}

p1 <- ggplot(data = data.frame(r = c(0,1)), mapping = aes(x = r)) +
  stat_function(
        fun = cdf_p(3),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = cdf_p(10),
        mapping = aes(color = "cb")) +
    stat_function(
        fun = cdf_p(100),
        mapping = aes(color = "cc")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(3, "Dark2"),
                     labels = c("3", "10", "100")) +
  xlab("r/R") + ylab("Relative volume") + theme_bw() +
  ggtitle("Volume in p dimensions") +
  theme(legend.position=c(0.2, 0.55))
  
  
p2 <- ggplot(data = data.frame(r = c(0,1)), mapping = aes(x = r)) +
  stat_function(
        fun = cdf_2(3),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = cdf_2(10),
        mapping = aes(color = "cb")) +
    stat_function(
        fun = cdf_2(100),
        mapping = aes(color = "cc")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(3, "Dark2"),
                     labels = c("3", "10", "100")) +
  xlab("r/R") + ylab("Relative volume") + theme_bw() +
  ggtitle("2D projected volume") +
  guides(color = FALSE)
  
grid.arrange(p1, p2, ncol=2)

```

## Radial transformation

Under the assumption that points are from a uniform distribution in a hypersphere, we can invert the piling effect using the CDF, i.e. the relative projected volume described in Eq. \ref{eq:cdf}. Starting from the distribution that arises for points that are uniform in the $p$-dimensional  hypersphere, we find the transformation of the radius in the 2-dimensional plane, $r$, that redistributes points such that they are uniform in a disk.

In practice we work with polar coordinates in the plane, $r, \theta$. The angular component $\theta$ is uniform for this distribution (by the rotation invariance of the sphere) and does not need to be transformed. The radial component $r$ is transformed by first calculating its CDF value to get a uniform distribution in $r''$,
\begin{equation}
r'' = V^{rel}_{2D} (r, p, R) = 1-\left(1-\left(\frac{r}{R}\right)^2\right)^{p/2}.
\end{equation}
We next transform $r''$ using the inverse of $V^{rel}_{2D} (r, 2, R)$ to go from a uniform distribution in radius to a uniform distribution across the area of the disk,
XXX notation: how to best write inverse here?
\begin{equation}
r' = V^{rel}_{2D} (r'', 2, R)^{-1} = R \sqrt{r''} = R \sqrt{1-\left(1-\left(\frac{r}{R}\right)^2\right)^{p/2}}.
\label{eq:resc}
\end{equation}

The relation between $r'$ and $r$ depends on the number of dimensions $p$, and is illustrated for selected values in Figure \ref{fig:radii}. We see that the transformation is approximately linear near the center. As $p$ increases it becomes non-linear faster, and e.g. for $p=10$ the points with radius $r>0.5$ will already be highly distorted and pushed out towards the last eighth in $r'$. Figure \ref{fig:circles} demonstrates this for different values of $p$ by showing equidistant circles for which the radius has been transformed according to Eq. \ref{eq:resc}.

```{r radii, fig.cap="Relation between $r$ and $r'$ for different values of $p$. The scaling is approximately linear near the center, but leads to distortion at large radii when $p$ is large.", fig.height=3, fig.width=6, out.width="60%", fig.align = "center"}
# define index as function of c
trans_p <- function(p){
  function(r){
    sqrt( 1 - (1-r^2)^(p/2))
  }
}
  
# plot dependence for selected values
ggplot(data = data.frame(x = c(0,1)), mapping = aes(x = x)) +
    stat_function(
        fun = trans_p(2),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = trans_p(4),
        mapping = aes(color = "cb")) +
  stat_function(
        fun = trans_p(6),
        mapping = aes(color = "cc")) +
    stat_function(
        fun = trans_p(10),
        mapping = aes(color = "cd")) +
    stat_function(
        fun = trans_p(20),
        mapping = aes(color = "ce")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(5, "Dark2"),
                     labels = c("2 (baseline)", "4", "6", "10", "20")) +
  xlab("r") + ylab("r'") + theme_bw()

```

```{r circles, fig.cap="Rescaled equidistant concentric circles, for $p=2, 3, 10, 100$. The circles remain equidistant for $p=2$ where no transformation is performed, and get pushed out towards the edge as $p$ increases."}

lbl <- c("p=2", "p=3", "p=10", "p=100")
names(lbl) <- c("p4", "p6", "p10", "p20")

tibble(x = 0, y = 0, r = seq(0.1, 1, length.out = 10)) %>%
  mutate(p4 = trans_p(2)(r)) %>%
  mutate(p6 = trans_p(3)(r)) %>%
  mutate(p10 = trans_p(10)(r)) %>%
  mutate(p20 = trans_p(100)(r)) %>%
  mutate(r = as.factor(r)) %>%
  pivot_longer(cols = starts_with(("p"))) %>%
  mutate(name = factor(name, levels = c("p4", "p6", "p10", "p20"))) %>%
  ggplot() +
  geom_circle(aes(x0=x, y0=y, r=value, color=r)) +
  coord_fixed() +
  theme_bw() +
  facet_wrap(~name, labeller = labeller(name = lbl)) +
  guides(color = FALSE) +
  theme(axis.title.x=element_blank(), axis.title.y=element_blank())

```

## Trimming and tuning {#sec:params}

Eq. \ref{eq:resc} is fixed for a given input dataset, by evaluating the number of dimensions $p$ and the maximum distance from the center $R$. However, in realistic applications we may wish to trim the projected data or tune the transformation. In practice, a combination of both adjustments can be used to further zoom in on the center of the distribution, or alternatively, to soften the transformation.

### Trimming
The overall scale of the transformation is determined by $R$. In the case of an approximately spherical and uniform distribution the maximum distance from the center works well and ensures the validity of the rescaling in Eq. \ref{eq:resc}. But this is not robust and might result in a much larger scale than desired, especially when it is determined by outlying observations.

We therefore allow trimming of the projected observations, using $R$ as a free parameter of the display function. When selecting a value $R$ that is smaller than the maximum distance from the center, we need to ensure that the projected radius of points is always smaller than $R$ before rescaling according to Eq. \ref{eq:resc}. We do this by replacing $r_i$ as
\begin{equation}
\tilde{r}_i = \min(r_i, R)
\label{eq:cutR}
\end{equation}
for each observation $i = 1, ..., n$.

### Tuning
The dimension of the input might not reflect the intrinsic dimensionality of the dataset. This could be the case when dimension reduction was used prior to visualization, e.g. displaying only the first few principal components. In this case the preferred effective dimensionality $p_{eff}$ is likely between the original number of dimensions and the selected number of principal components, since some directions would be considered pure noise, while others might still carry relevant information.

We allow tuning $p_{eff} = s p$ by selecting the scaling parameter $s$. By default, $s=1$ and $p_{eff}=p$. When $s<1$ the rescaling will be softer, and $s>1$ results in more aggressive rescaling than suggested by $p$ alone. Note that when $p_{eff} < 2$ we actually invert the behavior and shift the focus away from the center, in general this is not wanted.

```{r scaled, eval=F, fig.cap="Relation between $r$ and $r'$ for $p=10$ and different values of the scaling $s$. We can tune $s$ to control how strong the rescaling is, with $s<1$ leading to a weaker effect, and large values of $s$ increase the effect.", fig.height=3, fig.width=6, out.width="60%", fig.align = "center"}
# define index as function of c
trans_s <- function(s, p){
  p <- s * p
  function(r){
    sqrt( 1 - (1-r^2)^(p/2))
  }
}
  
# plot dependence for selected values
ggplot(data = data.frame(x = c(0,1)), mapping = aes(x = x)) +
    stat_function(
        fun = trans_s(0.2, 10),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = trans_s(0.5, 10),
        mapping = aes(color = "cb")) +
  stat_function(
        fun = trans_s(1, 10),
        mapping = aes(color = "cc")) +
    stat_function(
        fun = trans_s(2, 10),
        mapping = aes(color = "cd")) +
    stat_function(
        fun = trans_s(5, 10),
        mapping = aes(color = "ce")) +
  scale_color_manual(name = "s",
                     values = RColorBrewer::brewer.pal(5, "Dark2"),
                     labels = c("0.2", "0.5", "1", "2", "5")) +
  xlab("r") + ylab("r'") + theme_bw()

```


## Implementation as a dynamic display {#sec:implementation}

While the radial transformation can in general be used with any low-dimensional display that suffers from data piling, it is most useful when combined with a dynamic display showing a sequence of interpolated low-dimensional projections obtained when running a tour. We have implemented it as a new display method in the `display_sage` method in the `tourr` package [@tourr] in R [@rref].

We can think of the display functions as part of a data pipline obtained when running a tour. The initial step is pre-processing the data ($\mathbf{X}$, an $n \times p$ matrix), typically this includes centering and scaling using either the overall range or the variance. The tour is then looping over the following steps:

1. Obtain projection matrix $\mathbf{A}$. For $d$-dimensional projections this is an orthonormal $p \times d$ matrix. To ensure the smooth rotation of projections, each new $\mathbf{A}$ is obtained as an interpolated step in the sequence, as explained in @BCAH05.
2. Project the data by computing $\mathbf{Y} = \mathbf{X}\cdot\mathbf{A}$.
3. Map $\mathbf{Y}$ to the display to re-draw the projected data. We can think of the mapping as a function $f(\mathbf{Y})$, and for $d=2$ this typically maps the projected points onto a scatter plot display. Note that in general the mapping may also depend on additional information, for example @sliceTour is using the distance from the projection plane to show a slice display.

These three steps are available in the `tourr` package, which includes different options for basis selection, and different display functions. Since the implementation is modular, we can add the sage display as a new function on the projected data, $f(\mathbf{Y})$. This mapping is done in the following steps:

1. Center the 2-dimensional matrix $\mathbf{Y}$ and compute its polar coordinate representation $(r, \theta)$.
2. For each observation, first use Eq. \ref{eq:cutR} to ensure the radius $r$ is within the specified range, and then apply the radial transformation defined in Eq. \ref{eq:resc} to obtain $r'$.
3. Use the transformed radial coordinate $r'$ to re-compute the mapping onto Euclidean coordinates $(x, y)$.
4. To fit the final projection onto the plotting canvas ranging between $[-1,1]$, we rescale each observation by $0.9 \mathrm{half\_range}$.

The display can be added when calling the `animate` function in `tourr`, as


```{r codeExample, echo=TRUE, eval=FALSE}
tourr::animate(data, tour_path, display=display_sage(s, R, half_range))
```

and introduces the scaling parameter `s` for computing $p_{eff}$, and the overall scale `R` used for trimming. Both these parameters are described in Section \ref{sec:params} above. The ratio of `half_range` and `R` set the scale for fitting the displayed data on the plotting canvas, by default `half_range` = `R` and we apply the scaling factor $0.9$ to contain the projected points within the display. 

# Applications {#sec:application}

## Image classification

We can use the new display to look at different distribution of images from Google quickdraw (XXX REFERENCE). These are $28\times28=784$ pixel grey scale data, large dataset publicly available, here use small subset of three types of sketches (banana, cactus, crab) and observations (1000 sketches from each class) and see if we can separate the classes in the high-dimensional parameter space. We first reduce dimensionality using PCA and look at the first five PCs.

XXX is this a good example? can see that the fisheye display is using the space better, but I don't think we learn much more compared to what we see with the standard projected display...

```{r sketches, eval=F}
load("sketches_train.rda")
source("display-fisheye.R")
sk_small <- dplyr::filter(sketches, word %in% c("banana", "cactus", "crab")) %>%
  mutate(word = factor(word, levels = c("banana", "cactus", "crab")))
pal <- RColorBrewer::brewer.pal(3, "Dark2")
col <- pal[as.numeric(as.factor(sk_small$word))]
sk_pca <- prcomp(select(sk_small, -word, -id))
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
sk_5 <- sk_pca$x[,1:5] %>%
  as_tibble() %>%
  mutate_all(scale2)

set.seed(1006)
bases <- save_history(sk_5, max = 5)
tour_path <- interpolate(bases, 0.1)
d <- dim(tour_path)

render(sk_5, planned_tour(bases), display_fisheye(axes="bottomleft", col=col, s=1), "png", "pngs/sketches1-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)
render(sk_5, planned_tour(bases), display_fisheye(axes="bottomleft", col=col, s=2), "png", "pngs/sketches2-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)
render(sk_5, planned_tour(bases), display_xy(axes="bottomleft", col=col), "png", "pngs/sketches3-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)

```



# Discussion {#sec:concl}

Other transformations on the projected data?

