---
title: |
  Burning sage: Reversing the curse of dimensionality in the visualisation of high-dimensional data
type: Article
author:
  - name: Ursula Laa
    affil: a, b
    email: ursula.laa@monash.edu
  - name: Dianne Cook
    affil: b
    email: dicook@monash.edu
  - name: Stuart Lee
    affil: b, c
    email: stuart.lee1@monash.edu
affiliation:
  - num: a
    address: |
      School of Physics and Astronomy, Monash University
  - num: b
    address: |
      Department of Econometrics and Business Statistics, Monash University
  - num: c
    address: |
      Molecular Medicine Division, Walter and Eliza Hall Institute, Parkville, Australia
bibliography: biblio.bib
geometry: margin=2.5cm
abstract: |
  XXX
keywords: |
  data visualisation; grand tour; statistical computing; statistical graphics; multivariate data; dynamic graphics
header-includes: |
  \usepackage{hyperref}
  \usepackage[utf8]{inputenc}
  \def\tightlist{}
  \usepackage{setspace}
output: rticles::tf_article
keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(gridExtra)
library(ggforce)
library(tourr)
```

\doublespacing
# Introduction

The notion of a "curse of dimensionality" was originally introduced in @BellmanRichard1961 to describe the exponential growth in difficulty for optimization as number of dimensions increases. This affects sampling in high-dimensions. The volume of the space grows exponentially, with dimension, and since it is not typically feasible to increase the number of samples accordingly, the density of points decreases. The effect is that most points will be far from the sample mean, on the edge of the sample space. @doi:10.1111/j.1467-9868.2005.00510.x have shown that in the extreme case of high-dimension, low-sample size data, observations are on the vertices of a simplex. 

<!-- This causes problems in different domains. An important example in statistics is cluster analysis. Since the distance between any two points in a distribution becomes approximately constant, new methods are needed to cluster points in a high-dimensional space (see e.g. @Steinbach2004).-->

@Donoho00, conversely, considers the curse of dimensionality as a blessing, because the sparsity can be leveraged for computational efficiency. This is used in regularization methods, like lasso, to penalize model complexity. The penalty results in shrinking (some of) the parameter estimates towards zero.<!-- In ridge regression we obtain a global shrinkage, while Lasso can be thought of as variable selection and will shrink some of the estimates to zero. XXX mention concentration of measures?-->

Paradoxically, the curse of dimensionality inverts for dimension reduction, and affects the resulting visualizations. For low-dimensional linear projections of high-dimensional data, most projections will show approximately Gaussian distributions of the data, with observations concentrating in the center [@diaconis1984]. In projection pursuit, this motivated the development of indexes showing departure from normality. For high-dimension low-sample size data @10.2307/27639976,@10.1093/biomet/asp084 call this "data piling": all observations are in a single point in certain low-dimensional projections. These issues also persist with non-linear dimension reduction techniques. This is often referred to as the "crowding problem", which methods like t-Distributed Stochastic Neighbor Embedding (t-SNE) [@tsne] aim to alleviate.

XXX FIX - how can I make the contours better? Maybe get radial density and draw as circles?
For illustration we show two-dimensional linear projections of points sampled uniformly within hyperspheres in $p=3, 10, 100$ dimensions in Figure \ref{fig:density}. All distributions are uniform within the maximum radius $R=1$, but the projected points start piling near the center as $p$ increases.

```{r density, fig.cap="Two-dimensional projections of 10k points sampled uniformly within a $p$-dimensional hyperspheres, for $p=3, 10, 100$. The density is shown both through transparancy of the projected points, and as contour lines.", out.width="95%", fig.align = "center"}

lbl <- c("p=3", "p=10", "p=100")
names(lbl) <- c("p3", "p10", "p100")

n <- 10000

# sample points, only keep first two components for 2D projection
p3 <- geozoo::sphere.solid.random(3, n)$points[, c(1,2)]
p10 <- geozoo::sphere.solid.random(10, n)$points[, c(1,2)]
p100 <- geozoo::sphere.solid.random(100, n)$points[, c(1,2)]
colnames(p3) <- c("x", "y")
colnames(p10) <- c("x", "y")
colnames(p100) <- c("x", "y")

proj_points <- as_tibble(rbind(p3, p10, p100)) %>%
  add_column(p = c(rep(3, n), rep(10, n), rep(100, n)))


ggplot(proj_points, aes(x, y)) +
  geom_point(alpha=0.02) + 
  geom_density2d(bins = 7, contour_var = "count") +
  coord_fixed() +
  theme_bw() +
  facet_wrap(~p, labeller = labeller(name = lbl)) +
  guides(color = FALSE) +
  theme(axis.title.x=element_blank(), axis.title.y=element_blank())

```

In this work we address the piling in low-dimensional linear projections, which is in particular a barrier for viewing high-dimensional distributions with tour methods [@As85,@BCAH05]. Tours show interpolated sequences of low-dimensional projections of the data. When exploring a dataset with a tour we look at the distribution from different sides and want to discover features that may be visible from a specific viewing angle. However, these features may easily be hidden if most of the observations pile up near the center, while a large fraction of the plotting canvas will only show sparse outlying points. To counteract the effect, we introduce a radial transformation that redistributes data points after projecting them onto a two-dimensional plane, essentially zooming in near the center of the distribution.

XXXX needs to be updated
The paper is structured as follows: the radial transformation is described in Section \ref{sec:method}, the implementation as a new display function for the tourr package is described in Section \ref{sec:implementation}, and we show applications in Section \ref{sec:application}. We conclude in Section \ref{sec:concl}.

XXX probably remove this, for now keeping it in for reference
see also discussion in https://mc-stan.org/users/documentation/case-studies/curse-dims.html on the average length of multivariate normal vector for large $p$, relation to "concentration of measures".


# Burning sage algorithm {#sec:method}

To better understand the seemingly contradictory low density of points near the center in the high-dimensional space, versus the piling in low-dimensional projections, we consider the projected volume. For this, it is useful to think of the data as being distributed in a hypersphere, i.e. all data points are within a specified distance from the center. Compared to the common assumption of a distribution in a box or hypercube this has the advantage of being rotation invariant, and more accurately captures commonly observed distributions.

We can picture the linearly projected volume starting from a 3D sphere. In any 2D projection a large fraction of the volume will be projected onto a small region near the center of the resulting disc, as a consequence of the shape of the sphere. The volume will be further concentrated when projecting onto 1D instead. The same intuition holds as we increase the number of original dimensions that are projected down to one or two dimensions for visualization, with increasing fractions of the volume being projected onto a small area around the center.

XXX show density contours, similar to Fig. 3 - do this as a simulation, move to introduction

Here we introduce a radial transformation that redistributes the projected points, such that equal volume in the original ($p$-dimensional) space is projected onto equal area in a 2-dimensional projection. Note that it is straightforward to generalize this for $d$-dimensional projections by mapping onto equal $d$-dimensional volume instead.

## Relative volume

The radial dependence of the projected volume was described in @Laa:2020wkm through the ratio of the total volume of a $p$-dimensional sphere of radius $R$, $V(R, p)$ and its projected volume within a 2-dimensional radius $r$, $V_{2D}(r, R, p)$,
\begin{equation}
V^{rel}_{2D} (r, p, R) = \frac{V_{2D}(r, R, p)}{V(R, p)} = 1 - \left(1-\left(\frac{r}{R}\right)^2\right)^{p/2}.
\label{eq:cdf}
\end{equation}
This ratio is of particular interest because it gives the 2-dimensional radial cumulative distribution function (CDF) of points when assuming a uniform distribution within the $p$-dimensional hypersphere.

We compare $V^{rel}_{2D} (r, p, R)$ to the relative volume within a radius $r$ in the full hypersphere,
\begin{equation}
V^{rel}_{pD} (r, p, R) = \frac{V(r, p)}{V(R, p)} = \left({\frac{r}{R}}\right)^p,
\end{equation}
to illustrate the opposing effects on their distribution. This comparison is shown in Fig. \ref{fig:cdf}, for $p=3, 10, 100$. The left graph shows $V^{rel}_{pD} (r, p, R)$ and the right graph $V^{rel}_{2D} (r, p, R)$. We clearly see the opposing behavior of the two functions as $p$ increases. While $V^{rel}_{pD} (r, p, R)$ concentrates more and more towards large values of $r/R$, $V^{rel}_{2D} (r, p, R)$ has the opposite behavior. This concentration near the center of the disk is the result of integrating over all orthogonal directions when projecting onto the plane, and should be reversed by our radial transformation of the projected points.

```{r cdf, fig.cap="Comparing the relative volume of a $p$ dimensional hypersphere captured within a radius $r$, in the $p$-dimensional space (left) and in a 2-dimensional projection (right), for $p=3, 10, 100$. While most of the volume is squeezed towards larger values of $r$ as $p$ increases, the projected volume gets concentrated near the center instead.", fig.height=2.2, fig.width=6, out.width = "90%", fig.align = "center"}

cdf_2 <- function(p){
  function(r){
    1 - (1 - r^2)^(p/2)
  }
}

cdf_p <- function(p){
  function(r){
    r^p
  }
}

p1 <- ggplot(data = data.frame(r = c(0,1)), mapping = aes(x = r)) +
  stat_function(
        fun = cdf_p(3),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = cdf_p(10),
        mapping = aes(color = "cb")) +
    stat_function(
        fun = cdf_p(100),
        mapping = aes(color = "cc")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(3, "Dark2"),
                     labels = c("3", "10", "100")) +
  xlab("r/R") + ylab("Relative volume") + theme_bw() +
  ggtitle("Volume in p dimensions") +
  theme(legend.position=c(0.2, 0.55))
  
  
p2 <- ggplot(data = data.frame(r = c(0,1)), mapping = aes(x = r)) +
  stat_function(
        fun = cdf_2(3),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = cdf_2(10),
        mapping = aes(color = "cb")) +
    stat_function(
        fun = cdf_2(100),
        mapping = aes(color = "cc")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(3, "Dark2"),
                     labels = c("3", "10", "100")) +
  xlab("r/R") + ylab("Relative volume") + theme_bw() +
  ggtitle("2D projected volume") +
  guides(color = FALSE)
  
grid.arrange(p1, p2, ncol=2)

```

## Radial transformation

Under the assumption that points are from a uniform distribution in a hypersphere, we can invert the piling effect using the CDF, i.e. the relative projected volume described in Eq. \ref{eq:cdf}. Starting from the distribution that arises for points that are uniform in the $p$-dimensional  hypersphere, we find the transformation of the radius in the 2-dimensional plane, $r$, that redistributes points such that they are uniform in a disk.

In practice we work with polar coordinates in the plane, $r, \theta$. The angular component $\theta$ is uniform for this distribution (by the rotation invariance of the sphere) and does not need to be transformed. The radial component $r$ is transformed by first calculating its CDF value to get a uniform distribution in $r''$,
\begin{equation}
r'' = V^{rel}_{2D} (r, p, R) = 1-\left(1-\left(\frac{r}{R}\right)^2\right)^{p/2}.
\end{equation}
We next transform $r''$ using the inverse of $V^{rel}_{2D} (r, 2, R)$ to go from a uniform distribution in radius to a uniform distribution across the area of the disk,
XXX notation: how to best write inverse here?
\begin{equation}
r' = V^{rel}_{2D} (r'', 2, R)^{-1} = R \sqrt{r''} = R \sqrt{1-\left(1-\left(\frac{r}{R}\right)^2\right)^{p/2}}.
\label{eq:resc}
\end{equation}

The relation between $r'$ and $r$ depends on the number of dimensions $p$, and is illustrated for selected values in Figure \ref{fig:radii}. We see that the transformation is approximately linear near the center. As $p$ increases it becomes non-linear faster, and e.g. for $p=10$ the points with radius $r>0.5$ will already be highly distorted and pushed out towards the last eighth in $r'$. Figure \ref{fig:circles} demonstrates this for different values of $p$ by showing equidistant circles for which the radius has been transformed according to Eq. \ref{eq:resc}.

```{r radii, fig.cap="Relation between $r$ and $r'$ for different values of $p$. The scaling is approximately linear near the center, but leads to distortion at large radii when $p$ is large.", fig.height=3, fig.width=6, out.width="60%", fig.align = "center"}
# define index as function of c
trans_p <- function(p){
  function(r){
    sqrt( 1 - (1-r^2)^(p/2))
  }
}
  
# plot dependence for selected values
ggplot(data = data.frame(x = c(0,1)), mapping = aes(x = x)) +
    stat_function(
        fun = trans_p(2),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = trans_p(4),
        mapping = aes(color = "cb")) +
  stat_function(
        fun = trans_p(6),
        mapping = aes(color = "cc")) +
    stat_function(
        fun = trans_p(10),
        mapping = aes(color = "cd")) +
    stat_function(
        fun = trans_p(20),
        mapping = aes(color = "ce")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(5, "Dark2"),
                     labels = c("2 (baseline)", "4", "6", "10", "20")) +
  xlab("r") + ylab("r'") + theme_bw()

```

```{r circles, fig.cap="Rescaled equidistant concentric circles, for $p=2, 3, 10, 100$. The circles remain equidistant for $p=2$ where no transformation is performed, and get pushed out towards the edge as $p$ increases."}

lbl <- c("p=2", "p=3", "p=10", "p=100")
names(lbl) <- c("p4", "p6", "p10", "p20")

tibble(x = 0, y = 0, r = seq(0.1, 1, length.out = 10)) %>%
  mutate(p4 = trans_p(2)(r)) %>%
  mutate(p6 = trans_p(3)(r)) %>%
  mutate(p10 = trans_p(10)(r)) %>%
  mutate(p20 = trans_p(100)(r)) %>%
  mutate(r = as.factor(r)) %>%
  pivot_longer(cols = starts_with(("p"))) %>%
  mutate(name = factor(name, levels = c("p4", "p6", "p10", "p20"))) %>%
  ggplot() +
  geom_circle(aes(x0=x, y0=y, r=value, color=r)) +
  coord_fixed() +
  theme_bw() +
  facet_wrap(~name, labeller = labeller(name = lbl)) +
  guides(color = FALSE) +
  theme(axis.title.x=element_blank(), axis.title.y=element_blank())

```

## Trimming and tuning {#sec:params}

XXX split this into two separate subsections?

Eq. \ref{eq:resc} is fixed for a given input dataset, by evaluating the number of dimensions $p$ and the maximum distance from the center $R$. However, in realistic applications we may wish to tune the transformation.

For example, the dimension of the input might not reflect the intrinsic dimensionality of the dataset. This could be the case when dimension reduction was used prior to visualization, e.g. displaying only the first few principal components. In this case the preferred effective dimensionality $p_{eff}$ is likely between the original number of dimensions and the selected number of principal components, since some directions would be considered pure noise, while others might still carry relevant information.

Similarly, the overall scale of the transformation is determined by $R$. In the case of an approximately spherical and uniform distribution the maximum distance from the center works well and ensures the validity of the rescaling in Eq. \ref{eq:resc}. But it is not robust and might result in a much larger scale than desired, especially in the case of outlying observations. Tuning the scale would also allow increased zooming near the center without changing $p_{eff}$.
XXX When selecting a value $R$ that is smaller than the maximum distance from the center, we need to ensure that the projected radius of points is always smaller than $R$ before rescaling according to Eq. \ref{eq:resc}. We do this by replacing $r_i$ as
\begin{equation}
\tilde{r}_i = \min(r_i, R)
\end{equation}
for each observation $i = 1, ..., n$.

In practice we allow tuning $p_{eff} = s p$ by selecting the scaling parameter $s$. By default, $s=1$ and $p_{eff}=p$. When $s<1$ the rescaling will be softer, and $s>1$ results in more aggressive rescaling than suggested by $p$ alone. Note that when $p_{eff} < 2$ we actually invert the behavior and shift the focus away from the center, in general this is not wanted.

On the other hand, $R$ can be directly supplied by the user, and is set to the maximum distance from the center if no value is supplied. XXX it is important to ensure that all variables are on a comparable scale before applying this method!

```{r scaled, eval=F, fig.cap="Relation between $r$ and $r'$ for $p=10$ and different values of the scaling $s$. We can tune $s$ to control how strong the rescaling is, with $s<1$ leading to a weaker effect, and large values of $s$ increase the effect.", fig.height=3, fig.width=6, out.width="60%", fig.align = "center"}
# define index as function of c
trans_s <- function(s, p){
  p <- s * p
  function(r){
    sqrt( 1 - (1-r^2)^(p/2))
  }
}
  
# plot dependence for selected values
ggplot(data = data.frame(x = c(0,1)), mapping = aes(x = x)) +
    stat_function(
        fun = trans_s(0.2, 10),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = trans_s(0.5, 10),
        mapping = aes(color = "cb")) +
  stat_function(
        fun = trans_s(1, 10),
        mapping = aes(color = "cc")) +
    stat_function(
        fun = trans_s(2, 10),
        mapping = aes(color = "cd")) +
    stat_function(
        fun = trans_s(5, 10),
        mapping = aes(color = "ce")) +
  scale_color_manual(name = "s",
                     values = RColorBrewer::brewer.pal(5, "Dark2"),
                     labels = c("0.2", "0.5", "1", "2", "5")) +
  xlab("r") + ylab("r'") + theme_bw()

```


# Implementation {#sec:implementation}

XXX this should explain how the display integrates with the tour, in terms of a data pipeline: p-D data -> projection matrix from the tour -> d-D projected data -> radial transformation -> final display

XXX include short tour intro here with relevant references

XXX mention function, but full code should be in documentation

The sage display has been implemented in R [@rref] in the `display_sage` method in the `tourr` package [@tourr]. This display has two important new input parameters, the scaling `s` for computing $p_{eff}$, and the overall scale `R`. Both these parameters are described in Section \ref{sec:params} above.

Note that the ratio of the `tourr` parameter `half_range` and the new parameter `R` set the scale for fitting the displayed data on the plotting canvas ranging between $[-1,1]$. With the default settings `half_range` = `R` and we apply a scaling factor $0.9$ to contain the projected points within the display.

Below we show example code demonstrates how the new display redistributes the projected points drawn uniformly inside a 5D hypersphere.
```{r codeExampel, echo=TRUE, eval=FALSE}
# use geozoo to uniformly generate points inside a 5D sphere
sphere5 <- geozoo::sphere.solid.random(5)$points
colnames(sphere5) <- c("x1", "x2", "x3", "x4", "x5") # naming variables
# standard tour animation with default settings
animate_xy(sphere5)
# new sage display to redistribute the points based on projected volume
animate_sage(sphere5)
# we can use R and s to tune the display
# for example use R to zoom in near the center
# we also adjust half_range to fit the display on the plotting canvas
animate_sage(sphere5, R = 0.1, half_range = 0.1)
```


# Applications {#sec:application}

## Image classification

We can use the new display to look at different distribution of images from Google quickdraw (XXX REFERENCE). These are $28\times28=784$ pixel grey scale data, large dataset publicly available, here use small subset of three types of sketches (banana, cactus, crab) and observations (1000 sketches from each class) and see if we can separate the classes in the high-dimensional parameter space. We first reduce dimensionality using PCA and look at the first five PCs.

XXX is this a good example? can see that the fisheye display is using the space better, but I don't think we learn much more compared to what we see with the standard projected display...

```{r sketches, eval=F}
load("sketches_train.rda")
source("display-fisheye.R")
sk_small <- dplyr::filter(sketches, word %in% c("banana", "cactus", "crab")) %>%
  mutate(word = factor(word, levels = c("banana", "cactus", "crab")))
pal <- RColorBrewer::brewer.pal(3, "Dark2")
col <- pal[as.numeric(as.factor(sk_small$word))]
sk_pca <- prcomp(select(sk_small, -word, -id))
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
sk_5 <- sk_pca$x[,1:5] %>%
  as_tibble() %>%
  mutate_all(scale2)

set.seed(1006)
bases <- save_history(sk_5, max = 5)
tour_path <- interpolate(bases, 0.1)
d <- dim(tour_path)

render(sk_5, planned_tour(bases), display_fisheye(axes="bottomleft", col=col, s=1), "png", "pngs/sketches1-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)
render(sk_5, planned_tour(bases), display_fisheye(axes="bottomleft", col=col, s=2), "png", "pngs/sketches2-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)
render(sk_5, planned_tour(bases), display_xy(axes="bottomleft", col=col), "png", "pngs/sketches3-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)

```



# Discussion {#sec:concl}

Other transformations on the projected data?

