---
title: |
  Burning sage: Reversing the curse of dimensionality in the visualisation of high-dimensional data
type: Article
author:
  - name: Ursula Laa
    affil: a, b
    email: ursula.laa@monash.edu
  - name: Dianne Cook
    affil: b
    email: dicook@monash.edu
  - name: Stuart Lee
    affil: b, c
    email: stuart.lee1@monash.edu
affiliation:
  - num: a
    address: |
      School of Physics and Astronomy, Monash University
  - num: b
    address: |
      Department of Econometrics and Business Statistics, Monash University
  - num: c
    address: |
      Molecular Medicine Division, Walter and Eliza Hall Institute, Parkville, Australia
bibliography: biblio.bib
geometry: margin=2.5cm
abstract: |
  XXX
keywords: |
  data visualisation; grand tour; statistical computing; statistical graphics; multivariate data; dynamic graphics
header-includes: |
  \usepackage{hyperref}
  \usepackage[utf8]{inputenc}
  \def\tightlist{}
  \usepackage{setspace}
output: rticles::tf_article
keep_tex: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(tidyverse)
library(gridExtra)
library(ggforce)
library(tourr)
library(latex2exp)
```

\doublespacing
# Introduction

The notion of a "curse of dimensionality" was originally introduced in @BellmanRichard1961 to describe the exponential growth in difficulty for optimization as number of dimensions increases. This affects sampling in high-dimensions. The volume of the space grows exponentially, with dimension, and since it is not typically feasible to increase the number of samples accordingly, the density of points decreases. The effect is that most points will be far from the sample mean, on the edge of the sample space. @doi:10.1111/j.1467-9868.2005.00510.x have shown that in the extreme case of high-dimension, low-sample size data, observations are on the vertices of a simplex. 

<!-- This causes problems in different domains. An important example in statistics is cluster analysis. Since the distance between any two points in a distribution becomes approximately constant, new methods are needed to cluster points in a high-dimensional space (see e.g. @Steinbach2004).-->

@Donoho00, conversely, considers the curse of dimensionality as a blessing, because the sparsity can be leveraged for computational efficiency. This is used in regularization methods, like lasso, to penalize model complexity. The penalty results in shrinking (some of) the parameter estimates towards zero.<!-- In ridge regression we obtain a global shrinkage, while Lasso can be thought of as variable selection and will shrink some of the estimates to zero. XXX mention concentration of measures?-->

Paradoxically, the curse of dimensionality inverts for dimension reduction, and affects the resulting visualizations. For low-dimensional linear projections of high-dimensional data, most projections will show approximately Gaussian distributions of the data, with observations concentrating in the center [@diaconis1984]. In projection pursuit, this motivated the development of indexes showing departure from normality. For high-dimension low-sample size data @10.2307/27639976,@10.1093/biomet/asp084 call this "data piling": all observations are in a single point in certain low-dimensional projections. These issues also persist with non-linear dimension reduction techniques. This is often referred to as the "crowding problem", which methods like t-Distributed Stochastic Neighbor Embedding (t-SNE) [@tsne] aim to alleviate.

For illustration we show histograms of two-dimensional linear projections of points sampled uniformly within hyperspheres in $p=3, 10, 100$ dimensions in Figure \ref{fig:density}. All distributions are uniform within the maximum radius $R=1$, but the projected points start piling near the center as $p$ increases.

```{r density, fig.cap="Histogram of two-dimensional projections of 10k points sampled uniformly within a $p$-dimensional hyperspheres, for $p=3, 10, 100$. The fill color shows the logarithm of the bin count, with the highest counts shown in yellow. As $p$ increases the samples concentrate near the center.", out.width="95%", fig.width=6, fig.height=2, fig.align = "center"}

set.seed(12345)


n <- 10000

# sample points, only keep first two components for 2D projection
p3 <- geozoo::sphere.solid.random(3, n)$points[, c(1,2)]
p10 <- geozoo::sphere.solid.random(10, n)$points[, c(1,2)]
p100 <- geozoo::sphere.solid.random(100, n)$points[, c(1,2)]
colnames(p3) <- c("x", "y")
colnames(p10) <- c("x", "y")
colnames(p100) <- c("x", "y")

proj_points <- as_tibble(rbind(p3, p10, p100)) %>%
  mutate(p = factor(c(rep("p = 3", n), rep("p = 10", n), rep("p = 100", n)), levels = c("p = 3", "p = 10", "p = 100")))


ggplot(proj_points, aes(x, y)) +
  geom_hex(bins = 20, aes(fill=log(..count..))) +
  scale_fill_viridis_c() +
  theme_bw() +
  facet_wrap(~p, scales = "free") +
  guides(fill = FALSE) +
  theme_void() + 
  theme(#axis.title.x=element_blank(), 
        #axis.title.y=element_blank(), 
        aspect.ratio = 1)



```

In this work we address the piling in low-dimensional linear projections, which is in particular a barrier for viewing high-dimensional distributions with tour methods [@As85,@BCAH05]. Tours show interpolated sequences of low-dimensional projections of the data. When exploring a dataset with a tour we can discover features that are only visible from specific viewing angles. However, these features may easily be hidden if most of the observations pile up near the center, with a large fraction of the plotting canvas showing only outlying points. To counteract the effect, we introduce a radial transformation that zoomes in near the center of the distribution.

The paper is structured as follows: the radial transformation and its implementation is described in Section \ref{sec:method}, we show applications in Section \ref{sec:application} and conclude in Section \ref{sec:concl}.

XXX probably remove this, for now keeping it in for reference
see also discussion in https://mc-stan.org/users/documentation/case-studies/curse-dims.html on the average length of multivariate normal vector for large $p$, relation to "concentration of measures".


# Burning sage algorithm {#sec:method}

To understand why points tend to be away from the center in the high-dimensional space, but pile near the center in low-dimensional projections, we need to consider the projected volume. It is useful to think of the data as being distributed in a hypersphere, i.e. all data points are within a specified distance from the center. Compared to the common assumption of a distribution in a box or hypercube this has the advantage of being rotation invariant, and more accurately captures commonly observed distributions.

```{r, out.width="30%", fig.cap="Diagram illustrating volume vs projected volume for a 3D sphere. The full sphere has volume $V(R, p)$. Within a radius $r$ the sphere contains the reduced volume $V(r; p, R)$, but the projected volume within a radius $r$ in a 2D plane is much larger, $V_{2D}(r; p ,R)$.", fig.align = "center"}

xp <- 0.1
n <- 200

x <- seq(-xp, xp,length.out = n)
yp <- sqrt(1-x^2)
ym <- -yp

x_outer1 <- c(seq(1-xp, 1, length.out = n/2))
yp_outer1 <- sqrt(1-x_outer1^2)
ym_outer1 <- -yp_outer1

x_outer2 <- c(seq(-1, -1+xp, length.out = n/2))
yp_outer2 <- sqrt(1-x_outer2^2)
ym_outer2 <- -yp_outer2

ggplot() +
  geom_circle(aes(x0= 0, y0=0, r = 1)) +
  geom_circle(aes(x0= 0, y0=0, r = xp)) +
  geom_ellipse(aes(x0 = 0, y0 = 0, a = 1, b = 0.2, angle = 0)) +
  geom_ellipse(aes(x0 = 0, y0 = 0, a = xp, b = xp/5, angle = 0)) +
  geom_area(aes(x=x, y=yp), fill = "red", alpha = 0.5) +
  geom_area(aes(x=x, y=ym), fill = "red", alpha = 0.5) +
  geom_segment(aes(x = 0, y = 0, xend = 1, yend = 0),
               size = 0.5, arrow = arrow(length = unit(0.1, "inches"))) +
  annotate("text", x = 0.5, y = 0.05, label="R") +
  geom_segment(aes(x = 0, y = 0, xend = xp, yend = 0),
               size = 0.5, arrow = arrow(length = unit(0.1, "inches"))) +
  annotate("text", x = xp/2, y = 0.05, label="r") +
  annotate("text", x = 0, y = 0.5, label=TeX("$V_{2D}(r; p, R)$")) + 
  annotate("text", x = -0.2, y = 0.05, label=TeX("$V(r; p, R)$")) + 
  annotate("text", x = 0.5, y = 0.25, label="V(R,p)") +
  theme_void() +
  coord_fixed()


```

We can picture this for a 3D sphere. In any 2D projection a large fraction of the volume will be projected onto a small region near the center of the resulting disk. This is a consequence of the curved shape, which extends further in the orthogonal direction at the center of the disk, since the projection corresponds to an integration over the orthogonal space. The effect will be further enhanced when projecting onto 1D instead. The same intuition holds as we increase the number of original dimensions that are projected down to one or two dimensions for visualization, with increasing fractions of the volume being projected onto a small area around the center, see Figure \ref{fig:density} for illustration.

To offset this effect, we introduce a radial transformation that redistributes the projected points, such that equal volume in the original ($p$-dimensional) space is projected onto equal area in a 2-dimensional projection. Note that it is straightforward to generalize this for $d$-dimensional projections by mapping onto equal $d$-dimensional volume instead.

## Definition of the relative projected volume

To understand how the $p$ dimensional volume is projected onto a $2$ dimensional plane, we study what fraction of the total volume is projected onto the area of a disk depending on its radius. This dependence was desribed in @Laa:2020wkm. We start from a $p$ dimensional hypersphere with radius $R$ and volume $V(R, p)$, and its projected volume onto a centered $2$-dimensional disk of radius $r$, $V_{2D}(r; p, R)$, where $r$ can be any radius within $[0, R]$. The relative projected volume is then given as the ratio of these two quantities,
\begin{equation}
v_{2} (r; p, R) = \frac{V_{2D}(r; p, R)}{V(R, p)} = 1 - \left(1-\left(\frac{r}{R}\right)^2\right)^{p/2}.
\label{eq:cdf}
\end{equation}
This ratio is of particular interest because it gives the 2-dimensional radial cumulative distribution function (CDF) of points when assuming a uniform distribution within the $p$-dimensional hypersphere.

We can compare $v_{2} (r; p, R)$ to the relative volume within a radius $r$ in the original $p$-dimensional hypersphere,
\begin{equation}
v_{p} (r; p, R) = \frac{V(r, p)}{V(R, p)} = \left({\frac{r}{R}}\right)^p.
\end{equation}
This comparison is shown in Fig. \ref{fig:cdf}, for $p=3, 10, 100$. The left graph shows $v_{p} (r; p, R)$ and the right graph $v_{2} (r; p, R)$. We clearly see the opposing behavior of the two functions as $p$ increases. While $v_{p} (r; p, R)$ concentrates more and more towards large values of $r/R$, $v_{2} (r; p, R)$ has the inverse behavior.

```{r cdf, fig.cap="Comparing the relative volume of a $p$ dimensional hypersphere captured within a radius $r$, in the $p$-dimensional space (left) and in a 2-dimensional projection (right), for $p=3, 10, 100$. While most of the volume is squeezed towards larger values of $r$ as $p$ increases, the projected volume gets concentrated near the center instead.", fig.height=2.2, fig.width=6, out.width = "90%", fig.align = "center"}

cdf_2 <- function(p){
  function(r){
    1 - (1 - r^2)^(p/2)
  }
}

cdf_p <- function(p){
  function(r){
    r^p
  }
}

p1 <- ggplot(data = data.frame(r = c(0,1)), mapping = aes(x = r)) +
  stat_function(
        fun = cdf_p(3),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = cdf_p(10),
        mapping = aes(color = "cb")) +
    stat_function(
        fun = cdf_p(100),
        mapping = aes(color = "cc")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(3, "Dark2"),
                     labels = c("3", "10", "100")) +
  xlab("r/R") + ylab("Relative volume") + theme_bw() +
  ggtitle("Volume in p dimensions") +
  theme(legend.position=c(0.2, 0.55))
  
  
p2 <- ggplot(data = data.frame(r = c(0,1)), mapping = aes(x = r)) +
  stat_function(
        fun = cdf_2(3),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = cdf_2(10),
        mapping = aes(color = "cb")) +
    stat_function(
        fun = cdf_2(100),
        mapping = aes(color = "cc")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(3, "Dark2"),
                     labels = c("3", "10", "100")) +
  xlab("r/R") + ylab("Relative volume") + theme_bw() +
  ggtitle("2D projected volume") +
  guides(color = FALSE)
  
grid.arrange(p1, p2, ncol=2)

```

## Calculating the radial transformation

The aim of the algorithm is to redistribute the projected volume such that equal relative areas on the disk, as given by $v_{2} (r; p=2, R)= v_p(r; p=2, R) = (r/R)^2$, contain equal relative projected volume, given by $v_{2} (r; p, R)$. This is achieved through a transformation of the projected radius that can be defined for any $r\in[0,R]$, and is applied to the projected data points in the plane, $y = (y_1, y_2)$. We work with polar coordinates and represent the data points as $y = (r_y, \theta_y)$. The angular component $\theta_y$ is uniform for this distribution, by the rotation invariance of the sphere, and thus does not need to be transformed. The radial component $r_y$ is transformed in two steps.

The first transformation is to replace $r_y$ with $v_{2} (r_y; p, R)$. Since this is the radial CDF of the assumed underlying distribution, we expect that $v_{2} (r_y; p, R)$ is approximately uniformly distributed in radius. We then transform $v_{2} (r_y; p, R)$ using the inverse of $v_{2} (r_y; 2, R)$, to go from a uniform distribution in radius to a uniform distribution in area of the disk. This inverese is defined via
\begin{equation}
v_2^{-1}(v_2(r_y; 2, R); 2, R) = v_2(v_2^{-1}(r_y; 2, R); 2, R) = r_y
\end{equation}
and thus
\begin{equation}
v_2^{inv}(r_y; 2, R) = R \sqrt{r_y}.
\end{equation}

The full radial transformation is therefore given by 
\begin{equation}
r'_y = v_2^{inv} (v_2(r_y; p, R); 2, R) =  R \sqrt{v_2(r_y; p, R)} = R \sqrt{1-\left(1-\left(\frac{r_y}{R}\right)^2\right)^{p/2}}.
\label{eq:resc}
\end{equation}

The relation between $r'_y$ and $r_y$ depends on the number of dimensions $p$, and is illustrated for selected values in Figure \ref{fig:radii}. We see that the transformation is approximately linear near the center. As $p$ increases it becomes non-linear faster, and e.g. for $p=10$ the points with radius $r_x>0.5$ will already be highly distorted and pushed out towards the last eighth in $r'_x$. Figure \ref{fig:circles} demonstrates this for different values of $p$ by showing equidistant circles for which the radius has been transformed according to Eq. \ref{eq:resc}.

```{r radii, fig.cap="Relation between $r_y$ and $r'_y$ for different values of $p$ and assuming $R=1$. The scaling is approximately linear near the center, but leads to distortion at large radii when $p$ is large.", fig.height=3, fig.width=6, out.width="60%", fig.align = "center"}
# define index as function of c
trans_p <- function(p){
  function(r){
    sqrt( 1 - (1-r^2)^(p/2))
  }
}
  
# plot dependence for selected values
ggplot(data = data.frame(x = c(0,1)), mapping = aes(x = x)) +
    stat_function(
        fun = trans_p(2),
        mapping = aes(color = "ca")) +
  stat_function(
        fun = trans_p(4),
        mapping = aes(color = "cb")) +
  stat_function(
        fun = trans_p(6),
        mapping = aes(color = "cc")) +
    stat_function(
        fun = trans_p(10),
        mapping = aes(color = "cd")) +
    stat_function(
        fun = trans_p(20),
        mapping = aes(color = "ce")) +
  scale_color_manual(name = "p",
                     values = RColorBrewer::brewer.pal(5, "Dark2"),
                     labels = c("2 (baseline)", "4", "6", "10", "20")) +
  xlab(expression(r[y])) + ylab(expression(r[y]*minute)) + theme_bw()

```

```{r circles, fig.cap="Rescaled equidistant concentric circles, for $p=2, 3, 10, 100$. The circles remain equidistant for $p=2$ where no transformation is performed, and get pushed out towards the edge as $p$ increases.", out.width="75%", fig.align = "center"}

lbl <- c("p=2", "p=3", "p=10", "p=100")
names(lbl) <- c("p4", "p6", "p10", "p20")

tibble(x = 0, y = 0, r = seq(0.1, 1, length.out = 10)) %>%
  mutate(p4 = trans_p(2)(r)) %>%
  mutate(p6 = trans_p(3)(r)) %>%
  mutate(p10 = trans_p(10)(r)) %>%
  mutate(p20 = trans_p(100)(r)) %>%
  mutate(r = as.factor(r)) %>%
  pivot_longer(cols = starts_with(("p"))) %>%
  mutate(name = factor(name, levels = c("p4", "p6", "p10", "p20"))) %>%
  ggplot() +
  geom_circle(aes(x0=x, y0=y, r=value, color=r)) +
  coord_fixed() +
  theme_bw() +
  facet_wrap(~name, labeller = labeller(name = lbl)) +
  guides(color = FALSE) +
  theme(axis.title.x=element_blank(), axis.title.y=element_blank())

```

## Trimming and tuning {#sec:params}

The transformation in Eq. \ref{eq:resc} is fixed for a given input dataset, by evaluating the number of dimensions $p$ and the maximum distance from the center $R$. However, in realistic applications we may wish to trim the projected data or tune the transformation. In practice, a combination of both adjustments can be used to further zoom in on the center of the distribution, or alternatively, to soften the transformation.

### Trimming
The overall scale of the transformation is determined by $R$. In the case of an approximately spherical and uniform distribution the maximum distance from the center works well and ensures the validity of the rescaling in Eq. \ref{eq:resc}. But this is not robust and might result in a much larger scale than desired, especially when it is determined by outlying observations.

We therefore allow trimming of the projected observations, using $R$ as a free parameter of the display function. When selecting a value $R$ that is smaller than the maximum distance from the center, we need to ensure that the projected radius of points is always smaller than $R$, by trimming $r_y$ as
\begin{equation}
r_y^{\mathrm{trim}} = \min(r_y, R)
\label{eq:cutR}
\end{equation}
for each observation $x$.

### Tuning
The dimension of the input might not reflect the intrinsic dimensionality of the dataset. This could be the case when dimension reduction was used prior to visualization, e.g. displaying only the first few principal components. In this case the effective dimensionality $p_{\mathrm{eff}}$ is likely between the original number of dimensions and the selected number of principal components. We can think of omitted components as being in the orthogonal space of all considered projections, with some directions being pure noise, while others may still carry relevant information.

We allow tuning $p_{\mathrm{eff}} = \gamma p$ by selecting the scaling parameter $\gamma$. By default, $\gamma=1$ and $p_{\mathrm{eff}}=p$. When $\gamma<1$ the rescaling will be softer, and $\gamma>1$ results in more aggressive rescaling than suggested by $p$ alone. Note that when $p_{\mathrm{eff}} < 2$ we actually invert the behavior and shift the focus away from the center, in general this is not wanted.


## Implementation as a dynamic display {#sec:implementation}

While the radial transformation can in general be used with any low-dimensional display that suffers from data piling, it is most useful when combined with a dynamic display showing a sequence of interpolated low-dimensional projections obtained when running a tour. We have implemented it as a new display method `display_sage` in the `tourr` package [@tourr] in R [@rref].

We can think of the display functions as part of a data pipline obtained when running a tour. The initial step is pre-processing the data, given by $\mathbf{X}$, an $n \times p$ matrix containing $n$ observations in $p$ dimensions. Typically, this includes centering and scaling, using either the overall range or the variance. Ensuring a common scale of all variables, comparable to the selected scale parameter $R$, is especially important with the new display. The tour is then looping over the following steps:

1. Obtain projection matrix $\mathbf{A}$. For $d$-dimensional projections this is an orthonormal $p \times d$ matrix. To ensure the smooth rotation of projections, each new $\mathbf{A}$ is obtained as an interpolated step in the sequence, as explained in @BCAH05.
2. Project the data by computing $\mathbf{Y} = \mathbf{X}\cdot\mathbf{A}$.
3. Map $\mathbf{Y}$ to the display to re-draw the projected data. For $d=2$ this typically maps the projected points onto a scatter plot display. With the new display we first transform $\mathbf{Y}$ as:
    + Center the 2-dimensional matrix $\mathbf{Y}$ and compute its polar coordinate representation $(r_y, \theta_y)$.
    + For each observation, first use Eq. \ref{eq:cutR} to get the trimmed radius $r_y^{\mathrm{trim}}$  within the specified range, and then apply the radial transformation defined in Eq. \ref{eq:resc} to obtain $r'_y$.
    + Use the transformed radial coordinate $r'_y$ to re-compute the mapping onto Euclidean coordinates $(y_1, y_2)$.
4. To fit the final projection onto the plotting canvas ranging between $[-1,1]$, we rescale each mapped observation $y$ using a scaling parameter $s$.

The display can be added when calling the `animate` function in `tourr`, as


```{r codeExample, echo=TRUE, eval=FALSE}
tourr::animate(
  data,
  tour_path = tourr::grand_tour(),
  display = display_sage(gam, R, half_range)
  )
```

and uses `gam` to set the $\gamma$ parameter for computing $p_{\mathrm{eff}}$, and the overall range `R` used for trimming. Both these parameters are described in Section \ref{sec:params} above. Finally, `half_range` sets the scale parameter $s$ to adjust the scale to the drawing canvas. The ratio $R/s$ sets the scale for fitting the displayed data on the plotting canvas, by default $s = R$ and we apply the scaling factor $0.9$ to contain the projected points within the display. When adjusting $R$ the user should take care to adjust $s$ accordingly.

# Applications {#sec:application}

## Image classification

We can use the new display to look at different distribution of images from Google quickdraw (XXX REFERENCE). These are $28\times28=784$ pixel grey scale data, large dataset publicly available, here use small subset of three types of sketches (banana, cactus, crab) and observations (1000 sketches from each class) and see if we can separate the classes in the high-dimensional parameter space. We first reduce dimensionality using PCA and look at the first five PCs.

XXX is this a good example? can see that the fisheye display is using the space better, but I don't think we learn much more compared to what we see with the standard projected display...

```{r sketches, eval=F}
load("sketches_train.rda")
source("display-fisheye.R")
sk_small <- dplyr::filter(sketches, word %in% c("banana", "cactus", "crab")) %>%
  mutate(word = factor(word, levels = c("banana", "cactus", "crab")))
pal <- RColorBrewer::brewer.pal(3, "Dark2")
col <- pal[as.numeric(as.factor(sk_small$word))]
sk_pca <- prcomp(select(sk_small, -word, -id))
scale2 <- function(x, na.rm = FALSE) (x - mean(x, na.rm = na.rm)) / sd(x, na.rm)
sk_5 <- sk_pca$x[,1:5] %>%
  as_tibble() %>%
  mutate_all(scale2)

set.seed(1006)
bases <- save_history(sk_5, max = 5)
tour_path <- interpolate(bases, 0.1)
d <- dim(tour_path)

render(sk_5, planned_tour(bases), display_fisheye(axes="bottomleft", col=col, s=1), "png", "pngs/sketches1-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)
render(sk_5, planned_tour(bases), display_fisheye(axes="bottomleft", col=col, s=2), "png", "pngs/sketches2-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)
render(sk_5, planned_tour(bases), display_xy(axes="bottomleft", col=col), "png", "pngs/sketches3-%02d.png", apf=0.1, frames = d[3], rescale = FALSE)

```



# Discussion {#sec:concl}

Other transformations on the projected data?

